{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a52e601d",
   "metadata": {},
   "source": [
    "## GRAD CAM\n",
    "\n",
    "This code is an implementation of GRAD CAM the aim of the code is to provide visual explanation maps to a batch of test images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dd95b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary Libraries\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from scipy.misc import imread, imresize\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e02e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the model that you prefer to use\n",
    "\n",
    "# InputModel = tf.keras.applications.VGG16(\n",
    "#     include_top=True,\n",
    "#     weights=\"imagenet\",\n",
    "#     input_tensor=None,\n",
    "#     input_shape=None,\n",
    "#     pooling=None,\n",
    "#     classes=1000,\n",
    "#     classifier_activation=\"softmax\",\n",
    "# )\n",
    "\n",
    "InputModel = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "#     **kwargs\n",
    ")\n",
    "\n",
    "\n",
    "# InputModel = tf.keras.applications.ResNet50(\n",
    "#     include_top=True,\n",
    "#     weights=\"imagenet\",\n",
    "#     input_tensor=None,\n",
    "#     input_shape=None,\n",
    "#     pooling=None,\n",
    "#     classes=1000,\n",
    "#    # **kwargs\n",
    "# )\n",
    "\n",
    "\n",
    "# InputModel = tf.keras.applications.ResNet101(\n",
    "#     include_top=True,\n",
    "#     weights=\"imagenet\",\n",
    "#     input_tensor=None,\n",
    "#     input_shape=None,\n",
    "#     pooling=None,\n",
    "#     classes=1000,\n",
    "#    # **kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1646275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the various layers in the input model note down the name of the final convolutional layer \n",
    "\n",
    "InputModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f589ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  construct a loss function that returns the value at the output layer responsible for the given prediction  \n",
    "\n",
    "def target_category_loss(x, category_index, nb_classes):\n",
    "    return tf.multiply(x, K.one_hot([category_index], nb_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d93137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_category_loss_output_shape(input_shape):\n",
    "    return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    # Return L2 norm of the Input Tensor \n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e87f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRAD_CAM( x , layer_name  , Img   ):\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    prob = InputModel.predict(x)\n",
    "    input_img =  x\n",
    "    \n",
    "    k = 5\n",
    "    top_k = tf.keras.applications.imagenet_utils.decode_predictions(prob, k)\n",
    "    \n",
    "    predicted_class = np.argmax(prob)\n",
    "    layer_name = layer_name  \n",
    "    NumClasses = np.shape(prob)[1]\n",
    "    print(predicted_class)\n",
    "    \n",
    "#     print( InputModel.layers[-2].output)\n",
    "    \n",
    "    data = Img + \" \" + str(prob[0][predicted_class]) + \" \" + str(predicted_class) + \"\\n\"\n",
    "    \n",
    "#     file1.write( data )\n",
    "    \n",
    "    target_layer = lambda x: target_category_loss(x, predicted_class, NumClasses)\n",
    "    x = Lambda(target_layer, output_shape = target_category_loss_output_shape)(InputModel.output)\n",
    "    model = Model(inputs=InputModel.input, outputs=x)\n",
    "    \n",
    "    loss = K.sum(model.output)\n",
    "    \n",
    "    for l in model.layers:\n",
    "        \n",
    "        if( l.name == layer_name ):\n",
    "            conv_output = l.output\n",
    "    \n",
    "    grads = normalize(K.gradients(loss, conv_output)[0])\n",
    "    gradient_function = K.function([model.layers[0].input], [conv_output, grads])\n",
    "    \n",
    "    output, grads_val = gradient_function([input_img])\n",
    "    output = output[ 0 , :]\n",
    "    grads_val = grads_val[0 , :]\n",
    "    \n",
    "    weights_k_c = np.mean( grads_val , axis=(0 , 1 ) )\n",
    "    dim = np.shape(output)[0]\n",
    "    localization_result = np.ones( (dim, dim) , dtype =np.float32 )\n",
    "    \n",
    "    for i in range( len(weights_k_c)):\n",
    "        localization_result += weights_k_c[i]*output[: , : , i]\n",
    "\n",
    "    \n",
    "    localization_result = np.maximum (localization_result , 0 )\n",
    "    localization_result = localization_result / np.max(localization_result)\n",
    "    localization_result = resize(localization_result, (224,224))\n",
    "    cam3 = np.expand_dims(localization_result, axis=2)\n",
    "    cam3 = np.tile(cam3,[1,1,3])\n",
    "    \n",
    "    img_eval_average_drop = img.astype(float)\n",
    "\n",
    "    img_eval_average_drop /= img_eval_average_drop.max()\n",
    "    img_eval_average_drop = img_eval_average_drop*cam3\n",
    "    img_eval_average_drop /= img_eval_average_drop.max()\n",
    "    \n",
    "    print(\" Localization Map\")\n",
    "    io.imshow(cam3)\n",
    "    plt.show()\n",
    "    \n",
    "    GetSegmentation( cam3 , img  , Img )\n",
    "    \n",
    "    print( \"Overlaying on actual Image \")\n",
    "    \n",
    "    io.imshow(img_eval_average_drop)\n",
    "    plt.show()\n",
    "    \n",
    "    name = Img + \".png\"\n",
    "    path = \"Results/GRAD_CAM/\"\n",
    "    path = os.path.join( path, name)   \n",
    "#     cv2.imwrite(path , 255*img_eval_average_drop   )\n",
    "    \n",
    "    print(\"----------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSegmentation( cam3 , img , Img ):\n",
    "    \n",
    "    dim = np.shape(cam3)\n",
    "    img2 = img\n",
    "    alpha = 0.4\n",
    "    pixel_counter = 0 \n",
    "    \n",
    "    save_dir = '/Results'\n",
    "    save_dir = os.path.join(save_dir , Img  )\n",
    "    \n",
    "    for i in range( dim[0]):\n",
    "        for j in range( dim[1]):\n",
    "            if(  255*cam3[i][j][0] > 10 ):\n",
    "                img2[i][j] =  np.clip(alpha*img[i][j][0]  + (1- alpha) , 0, 255)  #img[i][j] +  [ 50, 0  , 0 ]\n",
    "                pixel_counter += 1 \n",
    "    \n",
    "    \n",
    "    print(\" Class specific Object Localization Result\")\n",
    "    img2 = cv2.cvtColor(img2 , cv2.COLOR_BGR2RGB ) \n",
    "#     cv2.imwrite( save_dir , img2 )\n",
    "    plt.imshow( img2 )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a25b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_data_dir = 'TestData'\n",
    "Imgs_names = os.listdir(test_data_dir)\n",
    "\n",
    "## According to the choosen model set appropriate name for the layer \n",
    "## EfficientNet = 'top_activation'\n",
    "## VGG = 'block5_pool'\n",
    "## Resnet50/101 = 'conv5_block3_out'\n",
    "\n",
    "\n",
    "layer_name = 'top_activation'\n",
    "\n",
    "\n",
    "\n",
    "# file1 = open(\"grad_cam_explanation.txt\",\"a\")\n",
    "\n",
    "for Img in Imgs_names:\n",
    "    \n",
    "    Img_path = os.path.join(test_data_dir , Img )\n",
    "    img = imread(Img_path, mode='RGB')\n",
    "    img = imresize(img, (224, 224))\n",
    "    x = np.expand_dims(img, axis=0) # [224,224 , 3 ] -> [1 , 224,224 , 3 ]\n",
    "    x = x[:,:,:,::-1]\n",
    "    GRAD_CAM( x , layer_name  , Img   )\n",
    "    \n",
    "# file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2827337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMAI",
   "language": "python",
   "name": "smai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
